{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMoVhWJmINNrtqv45lI4LQq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saurabh2086/whisper_use_case/blob/dev/whisper_speech_to_text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Se4IYKPdmNv8"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# on Ubuntu or Debian\n",
        "!sudo apt update && sudo apt install ffmpeg"
      ],
      "metadata": {
        "id": "QM7M8UFQmbxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "N_hnnLegmmnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "List the available models"
      ],
      "metadata": {
        "id": "FpsAyDuwnAcB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(dict(Models = whisper.available_models()))"
      ],
      "metadata": {
        "id": "4fOyQxA8m7Uy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "let's load the base model"
      ],
      "metadata": {
        "id": "QqPpzmCinxl6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recording live audio"
      ],
      "metadata": {
        "id": "wHdS8CQX4ZmS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install gradio -q"
      ],
      "metadata": {
        "id": "s1ylutEQ0bIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import spacy\n",
        "from spacy.matcher import Matcher, PhraseMatcher\n",
        "import time"
      ],
      "metadata": {
        "id": "AgcegtQy4cdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transcribe(file_name):\n",
        "  if file_name:\n",
        "    model = whisper.load_model(name='base')\n",
        "    result = model.transcribe(file_name)\n",
        "    result = result[\"text\"]\n",
        "  else:\n",
        "    result = None \n",
        "  return result\n",
        "\n",
        "# def gather_information(df_base,customer_id,\n",
        "#                        meeting_date,\n",
        "#                        short_term_goals, \n",
        "#                        long_term_goals, \n",
        "#                        happy_about, \n",
        "#                        not_happy_about, \n",
        "#                        next_steps):\n",
        "#   df = pd.DataFrame({'customer_ids':[customer_id],\n",
        "#              'meeting_date':[meeting_date],\n",
        "#              'short_term_goals':[short_term_goals], \n",
        "#              'long_term_goals':[long_term_goals],\n",
        "#              'happy_about':[happy_about],\n",
        "#              'not_happy_about':[not_happy_about],\n",
        "#              'next_steps':[next_steps]\n",
        "#   })\n",
        "#   df = df_base.append(df,ignore_index=True)\n",
        "#   return {rm_df: df,\n",
        "#           df_out: df}\n",
        "\n",
        "def find_information(text_transcript):\n",
        "  short_term_pattern = [{\"LOWER\":\"short\"}, {\"LOWER\": \"term\"}, {\"LEMMA\": \"goal\"}]\n",
        "  long_term_pattern = [{\"LOWER\":\"long\"}, {\"LOWER\": \"term\"}, {\"LEMMA\": \"goal\"}]\n",
        "  happy_pattern = [{\"LEMMA\": \"be\"}, {\"LOWER\": \"happy\"}, {\"LOWER\": \"about\"}]\n",
        "  not_happy_pattern = [{\"LEMMA\": \"be\"}, {\"LOWER\": \"not\"}, {\"LOWER\": \"happy\"}, {\"LOWER\": \"about\"}]\n",
        "  next_steps_pattern = [{\"LOWER\": \"next\"}, {\"LOWER\": \"step\"}]\n",
        "  whisper_pattern = [short_term_pattern,\n",
        "                   long_term_pattern,\n",
        "                   happy_pattern,\n",
        "                   not_happy_pattern,\n",
        "                   next_steps_pattern]\n",
        "\n",
        "  nlp=spacy.load(\"en_core_web_sm\")\n",
        "  doc = nlp(text_transcript)\n",
        "  matcher = Matcher(nlp.vocab)\n",
        "  matcher.add(\"WhisperPattern\", whisper_pattern)\n",
        "  matches = matcher(doc)\n",
        "  \n",
        "  initial_span = doc[0: matches[0][1]]\n",
        "  short_term_span = doc[matches[0][1]:matches[1][1]]\n",
        "  long_term_span = doc[matches[1][1]:matches[2][1]]\n",
        "  happy_span = doc[matches[2][1]:matches[3][1]]\n",
        "  not_happy_span = doc[matches[3][1]:matches[4][1]]\n",
        "  next_step_span = doc[matches[4][1]:]\n",
        "  \n",
        "  return [(initial_span.text, None),\n",
        "          (short_term_span.text, \"ShortTermGoals\"),\n",
        "          (long_term_span.text, \"LongTermGoals\"),\n",
        "          (happy_span.text, \"HappyAbout\"),\n",
        "          (not_happy_span.text, \"NotHappyAbout\"),\n",
        "          (next_step_span.text,\"NextSteps\")\n",
        "          ]\n",
        "\n",
        "def gather_information(df_base,customer_id,\n",
        "                       customer_name,\n",
        "                       meeting_date,\n",
        "                       meeting_time,\n",
        "                       transcription):\n",
        "  information = {k: v for (v,k) in find_information(transcription)}\n",
        "  \n",
        "  df = pd.DataFrame({'customer_ids':[customer_id],\n",
        "             'meeting_date':[meeting_date],\n",
        "             'meeting_time':[meeting_time],\n",
        "             'short_term_goals':[information[\"ShortTermGoals\"]], \n",
        "             'long_term_goals':[information[\"LongTermGoals\"]],\n",
        "             'happy_about':[information[\"HappyAbout\"]],\n",
        "             'not_happy_about':[information[\"NotHappyAbout\"]],\n",
        "             'next_steps':[information[\"NextSteps\"]],\n",
        "             'updated_on': [datetime.datetime.today()]\n",
        "  })\n",
        "  df = df_base.append(df,ignore_index=True)\n",
        "  return {rm_df: df,\n",
        "          df_out: df}\n",
        "\n"
      ],
      "metadata": {
        "id": "Mc6rVy6K6Aj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks(theme=gr.themes.Default()) as demo:\n",
        "  with gr.Tab(\"Rcord Meeting\"):  \n",
        "    gr.Markdown(\"## Emp Name: Miss Nobody\")\n",
        "    with gr.Row():\n",
        "      gr.Markdown(\"Emp ID: 324\")\n",
        "      gr.Markdown(\"Branch: Holland Village\")\n",
        "    gr.Markdown(\"---\")\n",
        "    with gr.Row():\n",
        "      with gr.Column():\n",
        "        customer_id = gr.Textbox(label=\"Customer ID\",type=\"text\", interactive=True)\n",
        "        customer_name = gr.Textbox(label=\"Customer Name\",type=\"text\", interactive=True)\n",
        "      with gr.Column():\n",
        "        meeting_date = gr.Textbox(placeholder=datetime.date.today(),label=\"Meeting time\", type=\"text\",interactive=True)\n",
        "        meeting_time = gr.Textbox(placeholder=datetime.datetime.now().strftime(\"%H:%M\"), label=\"Meeting time\", type=\"text\", interactive=True)\n",
        "    audio_record = gr.Audio(source=\"microphone\",label=\"Record the meeting\",type=\"filepath\")\n",
        "    transcription = gr.Textbox(label=\"Meeting notes\", type=\"text\", interactive=True, max_lines=5)\n",
        "    with gr.Row():\n",
        "      clear_button = gr.Button(\"Clear\")\n",
        "      parse_button = gr.Button(\"Parse Report\")\n",
        "\n",
        "    with gr.Accordion(\"See parsed report\"):\n",
        "      highlight_text = gr.HighlightedText()\n",
        "    submit_button = gr.Button(\"Submit Report\")\n",
        "\n",
        "\n",
        "    \n",
        "  with gr.Tab(\"Data\"):\n",
        "    rm_df = gr.State(pd.DataFrame())\n",
        "    df_out = gr.Dataframe()\n",
        "    \n",
        "  audio_record.change(transcribe,inputs=audio_record,outputs=transcription)\n",
        "  clear_button.click(lambda: (gr.update(value=None), \n",
        "                              gr.update(value=None), \n",
        "                              gr.update(value=None),\n",
        "                              gr.update(value=None)), \n",
        "                    None, \n",
        "                    [customer_id,\n",
        "                      customer_name, \n",
        "                      audio_record, \n",
        "                      transcription])\n",
        "  parse_button.click(find_information,inputs=transcription,outputs=[highlight_text])\n",
        "  submit_button.click(gather_information,inputs=[rm_df,customer_id, \n",
        "                                                 customer_name,\n",
        "                                                 meeting_date,\n",
        "                                                 meeting_time, \n",
        "                                                 transcription],outputs=[rm_df,df_out],show_progress=True)\n",
        "\n",
        "\n",
        "demo.launch(debug=False)"
      ],
      "metadata": {
        "id": "pjVTd4sGHBFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks(title=\"Voice To Text\") as demo:\n",
        "  rm_df = gr.State(pd.DataFrame())\n",
        "  with gr.Row():\n",
        "    customer_id = gr.Textbox(label=\"Customer ID\",type=\"text\")\n",
        "    meeting_date = gr.Textbox(value=datetime.date.today(),label=\"Meeting date\", type=\"text\")\n",
        "  short_term_goals = gr.Markdown(\"## Short Term Goals\")\n",
        "  with gr.Row():\n",
        "    input_audio1 = gr.Audio(source='microphone',label=\"Short Term Goals\", type=\"filepath\")\n",
        "    text_output1 = gr.Textbox(label=\"Short term goals\",interactive=True,type=\"text\")\n",
        "  \n",
        "  long_term_goals = gr.Markdown(\"## Long Term Goals\")\n",
        "  with gr.Row():\n",
        "    input_audio2 = gr.Audio(source='microphone',label=\"Long Term Goals\", type=\"filepath\",)\n",
        "    text_output2 = gr.Textbox(label=\"Long term goals\",interactive=True,type=\"text\")\n",
        "  \n",
        "  happy_about = gr.Markdown(\"## Things Client is happy about :)\")\n",
        "  with gr.Row():\n",
        "    input_audio3 = gr.Audio(source='microphone',label=\"Happy About\", type=\"filepath\",)\n",
        "    text_output3 = gr.Textbox(label=\"Things client is happy about\",interactive=True, type=\"text\")\n",
        "\n",
        "  happy_about = gr.Markdown(\"## Things Client is not happy about :(\")\n",
        "  with gr.Row():\n",
        "    input_audio4 = gr.Audio(source='microphone',label=\"Not Happy About\", type=\"filepath\",)\n",
        "    text_output4 = gr.Textbox(label=\"Things client is not happy about\",interactive=True, type=\"text\")\n",
        "\n",
        "  happy_about = gr.Markdown(\"## Next Steps ...\")\n",
        "  with gr.Row():\n",
        "    input_audio5 = gr.Audio(source='microphone',label=\"Next Steps\", type=\"filepath\",)\n",
        "    text_output5 = gr.Textbox(label=\"Next steps ...\",interactive=True, type=\"text\")\n",
        "  submit_button = gr.Button(\"Submit report\")\n",
        "  df_out = gr.Dataframe()\n",
        "\n",
        "\n",
        "\n",
        "  input_audio1.change(transcribe,inputs=input_audio1,outputs=text_output1)\n",
        "  input_audio2.change(transcribe,inputs=input_audio2,outputs=text_output2)\n",
        "  input_audio3.change(transcribe,inputs=input_audio3,outputs=text_output3)\n",
        "  input_audio4.change(transcribe,inputs=input_audio4,outputs=text_output4)\n",
        "  input_audio5.change(transcribe,inputs=input_audio5,outputs=text_output5)\n",
        "  submit_button.click(gather_information,\n",
        "                      inputs=[rm_df, customer_id,meeting_date,text_output1, text_output2, text_output3, text_output4, text_output5],\n",
        "                      outputs=[rm_df,df_out]\n",
        "                      )\n",
        "\n",
        "\n",
        "demo.launch(inbrowser=True, share=True)"
      ],
      "metadata": {
        "id": "F5BKr5y9ooAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.matcher import Matcher, PhraseMatcher"
      ],
      "metadata": {
        "id": "OvX0H48_LrQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"Hi, today I met a client at the Revo City branch and we had a discussion for about one hour. \n",
        "The name of the client was Mr. XYZ and we talked about various financial aspects of the client. \n",
        "Based on our discussion the short term goals of the client were to buy a house in the near future \n",
        "and he has been saving for that for quite a long time and now he has enough money for the down payment \n",
        "and he is looking for somebody, some bank to fund the loan. The long term goals of this client to the few \n",
        "long term plans like my sending his kids to college in the US and buying a few more investment properties as well as \n",
        "he wants to invest in bond. He is also concerned about insurance so currently he has medical insurance but he \n",
        "wants to take a life insurance as well that will cover him for life. He is looking for a term for maybe around \n",
        "99 years or something. The client is happy about  with HSBC that HSBC is in multiple countries so he wants to\n",
        "fund the EGA account using which he can have his money in various currencies. He also likes the network of HSBC and the \n",
        "services we provide. The thing he is not happy about the latency between fund transfers. Sometimes it takes one or \n",
        "two days for funds to reflect. He was asking if we have any plans to change that. On the next step I suggest \n",
        "that we should plan the insurance part of this client since the other plans are more merely short terms and \n",
        "for the long term plans we need to put the right insurance in place, and he requires more FX services in the future\"\"\""
      ],
      "metadata": {
        "id": "u1q7JcZwmbNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp=spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "TRbke65V5r9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(text)"
      ],
      "metadata": {
        "id": "hGs74nKebgOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matcher = Matcher(nlp.vocab)"
      ],
      "metadata": {
        "id": "zEepGSlVLipY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "short_term_pattern = [{\"LOWER\":\"short\"}, {\"LOWER\": \"term\"}, {\"LEMMA\": \"goal\"}]\n",
        "long_term_pattern = [{\"LOWER\":\"long\"}, {\"LOWER\": \"term\"}, {\"LEMMA\": \"goal\"}]\n",
        "happy_pattern = [{\"LEMMA\": \"be\"}, {\"LOWER\": \"happy\"}, {\"LOWER\": \"about\"}]\n",
        "not_happy_pattern = [{\"LEMMA\": \"be\"}, {\"LOWER\": \"not\"}, {\"LOWER\": \"happy\"}, {\"LOWER\": \"about\"}]\n",
        "next_steps_pattern = [{\"LOWER\": \"next\"}, {\"LOWER\": \"step\"}]"
      ],
      "metadata": {
        "id": "pPFOneLqLp6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "whisper_pattern = [short_term_pattern,\n",
        "                   long_term_pattern,\n",
        "                   happy_pattern,\n",
        "                   not_happy_pattern,\n",
        "                   next_steps_pattern]"
      ],
      "metadata": {
        "id": "9DfhFoXlkLcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matcher.add(\"WhisperPattern\", [short_term_pattern,\n",
        "                               long_term_pattern,\n",
        "                               happy_pattern,\n",
        "                               not_happy_pattern,\n",
        "                               next_steps_pattern])"
      ],
      "metadata": {
        "id": "CPfQ7tZNM9oD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matches = matcher(doc)"
      ],
      "metadata": {
        "id": "haMb6nLffdKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matches"
      ],
      "metadata": {
        "id": "s2ye89Pol5Ty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for match_id, start, end in matches:\n",
        "    string_id = nlp.vocab.strings[match_id]  # Get string representation\n",
        "    span = doc[start:end]  # The matched span\n",
        "    print(match_id, string_id, start, end, span.text)\n",
        "    "
      ],
      "metadata": {
        "id": "9x79Kmurcbff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matches[0][1]"
      ],
      "metadata": {
        "id": "OahRxDQvn2ST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_information(text_transcript):\n",
        "  short_term_pattern = [{\"LOWER\":\"short\"}, {\"LOWER\": \"term\"}, {\"LEMMA\": \"goal\"}]\n",
        "  long_term_pattern = [{\"LOWER\":\"long\"}, {\"LOWER\": \"term\"}, {\"LEMMA\": \"goal\"}]\n",
        "  happy_pattern = [{\"LEMMA\": \"be\"}, {\"LOWER\": \"happy\"}, {\"LOWER\": \"about\"}]\n",
        "  not_happy_pattern = [{\"LEMMA\": \"be\"}, {\"LOWER\": \"not\"}, {\"LOWER\": \"happy\"}, {\"LOWER\": \"about\"}]\n",
        "  next_steps_pattern = [{\"LOWER\": \"next\"}, {\"LOWER\": \"step\"}]\n",
        "  whisper_pattern = [short_term_pattern,\n",
        "                   long_term_pattern,\n",
        "                   happy_pattern,\n",
        "                   not_happy_pattern,\n",
        "                   next_steps_pattern]\n",
        "\n",
        "  nlp=spacy.load(\"en_core_web_sm\")\n",
        "  doc = nlp(text_transcript)\n",
        "  matcher = Matcher(nlp.vocab)\n",
        "  matcher.add(\"WhisperPattern\", whisper_pattern)\n",
        "  matches = matcher(doc)\n",
        "  \n",
        "  initial_span = doc[0: matches[0][1]]\n",
        "  short_term_span = doc[matches[0][1]:matches[1][1]]\n",
        "  long_term_span = doc[matches[1][1]:matches[2][1]]\n",
        "  happy_span = doc[matches[2][1]:matches[3][1]]\n",
        "  not_happy_span = doc[matches[3][1]:matches[4][1]]\n",
        "  next_step_span = doc[matches[4][1]:]\n",
        "  \n",
        "  return [(initial_span.text, None),\n",
        "          (short_term_span.text, \"ShortTermGoals\"),\n",
        "          (long_term_span.text, \"LongTermGoals\"),\n",
        "          (happy_span.text, \"HappyAbout\"),\n",
        "          (not_happy_span.text, \"NotHappyAbout\"),\n",
        "          (next_step_span.text,\"NextSteps\")\n",
        "          ]"
      ],
      "metadata": {
        "id": "XxQ3PpeEdgp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "\n",
        "def zip_to_json(file_obj):\n",
        "    files = []\n",
        "    with ZipFile(file_obj.name) as zfile:\n",
        "        for zinfo in zfile.infolist():\n",
        "            files.append(\n",
        "                {\n",
        "                    \"name\": zinfo.filename,\n",
        "                    \"file_size\": zinfo.file_size,\n",
        "                    \"compressed_size\": zinfo.compress_size,\n",
        "                }\n",
        "            )\n",
        "    return files\n",
        "\n",
        "\n",
        "demo = gr.Interface(zip_to_json, \"file\", \"json\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch()\n"
      ],
      "metadata": {
        "id": "h0xZGDFmGkQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rqbO4hBtDYMr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}