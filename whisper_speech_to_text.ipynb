{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOQok5s0RR58QvyrCiSV8F1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saurabh2086/whisper_use_case/blob/dev/whisper_speech_to_text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Se4IYKPdmNv8"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# on Ubuntu or Debian\n",
        "!sudo apt update && sudo apt install ffmpeg"
      ],
      "metadata": {
        "id": "QM7M8UFQmbxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "N_hnnLegmmnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "List the available models"
      ],
      "metadata": {
        "id": "FpsAyDuwnAcB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(dict(Models = whisper.available_models()))"
      ],
      "metadata": {
        "id": "4fOyQxA8m7Uy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "let's load the base model"
      ],
      "metadata": {
        "id": "QqPpzmCinxl6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = whisper.load_model(name='base')"
      ],
      "metadata": {
        "id": "h6uPtD08nOol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check if the model is running on the GPU. The output should be `device(type='cuda', index=0)`"
      ],
      "metadata": {
        "id": "4AwVsus7pJYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.device"
      ],
      "metadata": {
        "id": "4fNFcjPipF2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio\n",
        "Audio(\"mary.mp3\")"
      ],
      "metadata": {
        "id": "WBpsx3Y-pRpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load audio and pad/trim it to fit 30 seconds\n"
      ],
      "metadata": {
        "id": "DMcCBjCpsimh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mary = whisper.load_audio(\"mary.mp3\")\n",
        "audio = whisper.pad_or_trim(mary)"
      ],
      "metadata": {
        "id": "6ukXvHKnrsEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make log-Mel spectrogram and move to the same device as the model\n"
      ],
      "metadata": {
        "id": "fONAdjPZso7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mel = whisper.log_mel_spectrogram(audio).to(model.device)"
      ],
      "metadata": {
        "id": "C8oujk-tsbZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mel.shape"
      ],
      "metadata": {
        "id": "8FutZeD4xrEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "detect the spoken language"
      ],
      "metadata": {
        "id": "xITMcuCQtM3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_, probs = model.detect_language(mel)\n",
        "print(f\"Detected language: {max(probs,key=probs.get)}\")"
      ],
      "metadata": {
        "id": "3I_YpIm6tEV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decode the audio"
      ],
      "metadata": {
        "id": "oImQVuJuw8fn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "options = whisper.DecodingOptions(task=\"transcribe\") \n",
        "result = whisper.decode(model=model,mel=mel,options=options)"
      ],
      "metadata": {
        "id": "uZ9lmVMJtnOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"The Transcription : \\n{result.text}\")"
      ],
      "metadata": {
        "id": "YaF3uAN1xIUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the transcribe method"
      ],
      "metadata": {
        "id": "rW2TRf-CzmQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Audio(\"daisy_HAL_9000.mp3\")"
      ],
      "metadata": {
        "id": "Uzri3XNp0tXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.transcribe(\"daisy_HAL_9000.mp3\")\n",
        "print(result[\"text\"])"
      ],
      "metadata": {
        "id": "MOYFiW4FxkRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spacy - Extracting information"
      ],
      "metadata": {
        "id": "SbmueUyVj7e2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R2ACwpJ_j6BX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recording live audio"
      ],
      "metadata": {
        "id": "wHdS8CQX4ZmS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install gradio -q"
      ],
      "metadata": {
        "id": "s1ylutEQ0bIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import time"
      ],
      "metadata": {
        "id": "AgcegtQy4cdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transcribe(file_name):\n",
        "  if file_name:\n",
        "    model = whisper.load_model(name='base')\n",
        "    result = model.transcribe(file_name)\n",
        "    result = result[\"text\"]\n",
        "  else:\n",
        "    result = None \n",
        "  return result\n",
        "\n",
        "def gather_information(df_base,customer_id,\n",
        "                       meeting_date,\n",
        "                       short_term_goals, \n",
        "                       long_term_goals, \n",
        "                       happy_about, \n",
        "                       not_happy_about, \n",
        "                       next_steps):\n",
        "  df = pd.DataFrame({'customer_ids':[customer_id],\n",
        "             'meeting_date':[meeting_date],\n",
        "             'short_term_goals':[short_term_goals], \n",
        "             'long_term_goals':[long_term_goals],\n",
        "             'happy_about':[happy_about],\n",
        "             'not_happy_about':[not_happy_about],\n",
        "             'next_steps':[next_steps]\n",
        "  })\n",
        "  df = df_base.append(df,ignore_index=True)\n",
        "  return {rm_df: df,\n",
        "          df_out: df}\n",
        "  "
      ],
      "metadata": {
        "id": "Mc6rVy6K6Aj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks(theme=gr.themes.Default()) as demo:\n",
        "  rm_df = gr.State(pd.DataFrame())\n",
        "  gr.Markdown(\"## Emp Name: Miss Nobody\")\n",
        "  with gr.Row():\n",
        "    gr.Markdown(\"Emp ID: 324\")\n",
        "    gr.Markdown(\"Branch: Holland Village\")\n",
        "  gr.Markdown(\"---\")\n",
        "  with gr.Row():\n",
        "    with gr.Column():\n",
        "      customer_id = gr.Textbox(label=\"Customer ID\",type=\"text\", interactive=True)\n",
        "      customer_name = gr.Textbox(label=\"Customer Name\",type=\"text\", interactive=True)\n",
        "    with gr.Column():\n",
        "      meeting_date = gr.Textbox(placeholder=datetime.date.today(),label=\"Meeting time\", type=\"text\",interactive=True)\n",
        "      meeting_time = gr.Textbox(placeholder=datetime.datetime.now().strftime(\"%H:%M\"), label=\"Meeting time\", type=\"text\", interactive=True)\n",
        "  \n",
        "  with gr.Row():\n",
        "    audio_record = gr.Audio(source=\"microphone\",label=\"Record the meeting\",type=\"filepath\")\n",
        "    transcription = gr.Textbox(label=\"Meeting notes\", type=\"text\", interactive=True)\n",
        "  clear_button = gr.Button(\"Clear\")\n",
        "\n",
        "  audio_record.change(transcribe,inputs=audio_record,outputs=transcription)\n",
        "  # audio_record.clear()\n",
        "  clear_button.click(lambda: (gr.update(value=None), \n",
        "                              gr.update(value=None), \n",
        "                              gr.update(value=None),\n",
        "                              gr.update(value=None)), \n",
        "                     None, \n",
        "                     [customer_id,\n",
        "                      customer_name, \n",
        "                      audio_record, \n",
        "                      transcription])\n",
        "demo.launch(debug=False)"
      ],
      "metadata": {
        "id": "pjVTd4sGHBFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks(title=\"Voice To Text\") as demo:\n",
        "  rm_df = gr.State(pd.DataFrame())\n",
        "  with gr.Row():\n",
        "    customer_id = gr.Textbox(label=\"Customer ID\",type=\"text\")\n",
        "    meeting_date = gr.Textbox(value=datetime.date.today(),label=\"Meeting date\", type=\"text\")\n",
        "  short_term_goals = gr.Markdown(\"## Short Term Goals\")\n",
        "  with gr.Row():\n",
        "    input_audio1 = gr.Audio(source='microphone',label=\"Short Term Goals\", type=\"filepath\")\n",
        "    text_output1 = gr.Textbox(label=\"Short term goals\",interactive=True,type=\"text\")\n",
        "  \n",
        "  long_term_goals = gr.Markdown(\"## Long Term Goals\")\n",
        "  with gr.Row():\n",
        "    input_audio2 = gr.Audio(source='microphone',label=\"Long Term Goals\", type=\"filepath\",)\n",
        "    text_output2 = gr.Textbox(label=\"Long term goals\",interactive=True,type=\"text\")\n",
        "  \n",
        "  happy_about = gr.Markdown(\"## Things Client is happy about :)\")\n",
        "  with gr.Row():\n",
        "    input_audio3 = gr.Audio(source='microphone',label=\"Happy About\", type=\"filepath\",)\n",
        "    text_output3 = gr.Textbox(label=\"Things client is happy about\",interactive=True, type=\"text\")\n",
        "\n",
        "  happy_about = gr.Markdown(\"## Things Client is not happy about :(\")\n",
        "  with gr.Row():\n",
        "    input_audio4 = gr.Audio(source='microphone',label=\"Not Happy About\", type=\"filepath\",)\n",
        "    text_output4 = gr.Textbox(label=\"Things client is not happy about\",interactive=True, type=\"text\")\n",
        "\n",
        "  happy_about = gr.Markdown(\"## Next Steps ...\")\n",
        "  with gr.Row():\n",
        "    input_audio5 = gr.Audio(source='microphone',label=\"Next Steps\", type=\"filepath\",)\n",
        "    text_output5 = gr.Textbox(label=\"Next steps ...\",interactive=True, type=\"text\")\n",
        "  submit_button = gr.Button(\"Submit report\")\n",
        "  df_out = gr.Dataframe()\n",
        "\n",
        "\n",
        "\n",
        "  input_audio1.change(transcribe,inputs=input_audio1,outputs=text_output1)\n",
        "  input_audio2.change(transcribe,inputs=input_audio2,outputs=text_output2)\n",
        "  input_audio3.change(transcribe,inputs=input_audio3,outputs=text_output3)\n",
        "  input_audio4.change(transcribe,inputs=input_audio4,outputs=text_output4)\n",
        "  input_audio5.change(transcribe,inputs=input_audio5,outputs=text_output5)\n",
        "  submit_button.click(gather_information,\n",
        "                      inputs=[rm_df, customer_id,meeting_date,text_output1, text_output2, text_output3, text_output4, text_output5],\n",
        "                      outputs=[rm_df,df_out]\n",
        "                      )\n",
        "\n",
        "\n",
        "demo.launch(inbrowser=True, share=True)"
      ],
      "metadata": {
        "id": "F5BKr5y9ooAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.Interface(\n",
        "    title = \"Whisper AI app\",\n",
        "    fn = transcribe,\n",
        "    inputs = [gr.inputs.Audio(source=\"microphone\", type=\"filepath\")],\n",
        "    outputs=[\"textbox\"],\n",
        "    live=True\n",
        ").launch()"
      ],
      "metadata": {
        "id": "RP5wUrmG4qJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/whisper.git \n",
        "!sudo apt update && sudo apt install ffmpeg\n",
        "\n",
        "import whisper\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import time\n",
        "\n",
        "def transcribe(file_name):\n",
        "  model = whisper.load_model(name='base')\n",
        "  result = model.transcribe(file_name)\n",
        "  return result[\"text\"]\n",
        "\n",
        "def gather_information(df_base,customer_id,\n",
        "                       meeting_date,\n",
        "                       short_term_goals, \n",
        "                       long_term_goals, \n",
        "                       happy_about, \n",
        "                       not_happy_about, \n",
        "                       next_steps):\n",
        "  df = pd.DataFrame({'customer_ids':[customer_id],\n",
        "             'meeting_date':[meeting_date],\n",
        "             'short_term_goals':[short_term_goals], \n",
        "             'long_term_goals':[long_term_goals],\n",
        "             'happy_about':[happy_about],\n",
        "             'not_happy_about':[not_happy_about],\n",
        "             'next_steps':[next_steps]\n",
        "  })\n",
        "  df = df_base.append(df,ignore_index=True)\n",
        "  return {rm_df: df,\n",
        "          df_out: df}\n",
        "\n",
        "with gr.Blocks(title=\"Voice To Text\") as demo:\n",
        "  rm_df = gr.State(pd.DataFrame())\n",
        "  with gr.Row():\n",
        "    customer_id = gr.Textbox(label=\"Customer ID\",type=\"text\")\n",
        "    meeting_date = gr.Textbox(value=datetime.date.today(),label=\"Meeting date\", type=\"text\")\n",
        "  short_term_goals = gr.Markdown(\"## Short Term Goals\")\n",
        "  with gr.Row():\n",
        "    input_audio1 = gr.Audio(source='microphone',label=\"Short Term Goals\", type=\"filepath\")\n",
        "    text_output1 = gr.Textbox(label=\"Short term goals\",interactive=True,type=\"text\")\n",
        "  \n",
        "  long_term_goals = gr.Markdown(\"## Long Term Goals\")\n",
        "  with gr.Row():\n",
        "    input_audio2 = gr.Audio(source='microphone',label=\"Long Term Goals\", type=\"filepath\",)\n",
        "    text_output2 = gr.Textbox(label=\"Long term goals\",interactive=True,type=\"text\")\n",
        "  \n",
        "  happy_about = gr.Markdown(\"## Things Client is happy about :)\")\n",
        "  with gr.Row():\n",
        "    input_audio3 = gr.Audio(source='microphone',label=\"Happy About\", type=\"filepath\",)\n",
        "    text_output3 = gr.Textbox(label=\"Things client is happy about\",interactive=True, type=\"text\")\n",
        "\n",
        "  happy_about = gr.Markdown(\"## Things Client is not happy about :(\")\n",
        "  with gr.Row():\n",
        "    input_audio4 = gr.Audio(source='microphone',label=\"Not Happy About\", type=\"filepath\",)\n",
        "    text_output4 = gr.Textbox(label=\"Things client is not happy about\",interactive=True, type=\"text\")\n",
        "\n",
        "  happy_about = gr.Markdown(\"## Next Steps ...\")\n",
        "  with gr.Row():\n",
        "    input_audio5 = gr.Audio(source='microphone',label=\"Next Steps\", type=\"filepath\",)\n",
        "    text_output5 = gr.Textbox(label=\"Next steps ...\",interactive=True, type=\"text\")\n",
        "  submit_button = gr.Button(\"Submit report\")\n",
        "  df_out = gr.Dataframe()\n",
        "\n",
        "\n",
        "\n",
        "  input_audio1.change(transcribe,inputs=input_audio1,outputs=text_output1)\n",
        "  input_audio2.change(transcribe,inputs=input_audio2,outputs=text_output2)\n",
        "  input_audio3.change(transcribe,inputs=input_audio3,outputs=text_output3)\n",
        "  input_audio4.change(transcribe,inputs=input_audio4,outputs=text_output4)\n",
        "  input_audio5.change(transcribe,inputs=input_audio5,outputs=text_output5)\n",
        "  submit_button.click(gather_information,\n",
        "                      inputs=[rm_df, customer_id,meeting_date,text_output1, text_output2, text_output3, text_output4, text_output5],\n",
        "                      outputs=[rm_df,df_out]\n",
        "                      )\n",
        "\n",
        "\n",
        "demo.launch(inbrowser=True, share=True, auth=(\"baby_shark\",\"dododododo\"))\n",
        "\n"
      ],
      "metadata": {
        "id": "iU1OLUPj5b57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u1q7JcZwmbNL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}